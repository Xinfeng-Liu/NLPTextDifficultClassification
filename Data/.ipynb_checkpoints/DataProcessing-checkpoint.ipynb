{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fd8c7c0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import model_selection, preprocessing, linear_model, naive_bayes, metrics, svm\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn import decomposition, ensemble\n",
    "from collections import defaultdict\n",
    "import textblob\n",
    "import string\n",
    "import nltk\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn import preprocessing\n",
    "import regex as re\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26730436",
   "metadata": {},
   "source": [
    "# Content\n",
    "\n",
    "## 1. [Data Preparation](#1.-Data-Preparation)\n",
    "## 2. [Data Processing](#2.-Data-Processing)\n",
    "* [2.1 Count Vectors](#2.1-Count-Vectors)\n",
    "* [2.2 TF-IDF as feature](#2.2-TF-IDF-as-feature)\n",
    "* [2.3 Create Text/NLP Based Features](#2.3-Create-Text/NLP-Based-Features)\n",
    "    * [2.3.1 Char/Word Count](#2.3.1-Char/Word-Count)\n",
    "    * [2.3.2 Speech Tag Count](#2.3.2-Speech-Tag-Count)\n",
    "\n",
    "## 3. [Model Building](#3.-Model-Building)\n",
    "* [3.1 Dummy Classifier](#3.1-Dummy-Classifier)\n",
    "* [3.2 Logistic Regression Clasifier](#3.2-Logistic-Regression-Clasifier)\n",
    "* [3.3 SVM](#3.3-SVM)\n",
    "* [3.4 KNN](#3.4-KNN)\n",
    "* [3.5 Decision Tree](#3.5-Decision-Tree)\n",
    "* [3.6 Random Forest](#3.6-Random-Forest)\n",
    "* [3.7 AdaBoost](#3.7-AdaBoost)\n",
    "* [3.8 XGBoost](#3.8-XGBoost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4c4c61a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read file\n",
    "df = pd.read_csv('WikiLarge_Train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "54d0afd0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>original_text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>There is manuscript evidence that Austen conti...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>In a remarkable comparative analysis , Mandaea...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Before Persephone was released to Hermes , who...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Cogeneration plants are commonly found in dist...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Geneva -LRB- , ; , ; , ; ; -RRB- is the second...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       original_text  label\n",
       "0  There is manuscript evidence that Austen conti...      1\n",
       "1  In a remarkable comparative analysis , Mandaea...      1\n",
       "2  Before Persephone was released to Hermes , who...      1\n",
       "3  Cogeneration plants are commonly found in dist...      1\n",
       "4  Geneva -LRB- , ; , ; , ; ; -RRB- is the second...      1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6a3a1c4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df['label'].value_counts().plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "737d72d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/8_/j14vrxnx2cz8yhy96kx5x_3h0000gn/T/ipykernel_74229/687694840.py:6: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df['modified_txt'] = df['modified_txt'].str.replace(r'[^\\w\\s]+', '')\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/xinfengliu/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# change all characters to lower case\n",
    "df['modified_txt'] = df['original_text']\n",
    "df['modified_txt'] = df['modified_txt'].str.lower()\n",
    "\n",
    "# remove punctuation\n",
    "df['modified_txt'] = df['modified_txt'].str.replace(r'[^\\w\\s]+', '')\n",
    "\n",
    "# remove stop words\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "stop = stopwords.words('english')\n",
    "\n",
    "df['modified_txt'] = df['modified_txt'].apply(lambda x: ' '.join([word for word in x.split() if not word in stop]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0d8184a",
   "metadata": {},
   "source": [
    "# 1. Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "38d282f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ctreate train data and test data\n",
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(df['modified_txt'], \n",
    "                                                                    df['label'], \n",
    "                                                                    train_size=0.75, \n",
    "                                                                    random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ac4f29d",
   "metadata": {},
   "source": [
    "# 2. Data Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72174ac0",
   "metadata": {},
   "source": [
    "* 2.1 Count Vectors as features\n",
    "* 2.2 TF-IDF Vectors as features\n",
    "    * Word level\n",
    "    * N-Gram level\n",
    "    * Character level\n",
    "* 2.3 Word Embeddings as features\n",
    "* 2.4 Text / NLP based features\n",
    "* 2.5 Topic Models as features\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86cda4ff",
   "metadata": {},
   "source": [
    "## 2.1 Count Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "280c2101",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a count vectorizer object\n",
    "count_vect = CountVectorizer(analyzer='word', token_pattern=r'\\w{1,}')\n",
    "count_vect.fit(df['modified_txt'])\n",
    "\n",
    "# transform the training and testing data using count vectorizer object\n",
    "X_train_count = count_vect.transform(X_train)\n",
    "X_test_count = count_vect.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec341349",
   "metadata": {},
   "source": [
    "## 2.2 TF-IDF as feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a3be51a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vect = TfidfVectorizer(analyzer='word', token_pattern=r'\\w{1,}', max_features=5000)\n",
    "tfidf_vect.fit(df['modified_txt'])\n",
    "X_train_tfidf = tfidf_vect.transform(X_train)\n",
    "X_test_tfidf = tfidf_vect.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f5bc1a3",
   "metadata": {},
   "source": [
    "## 2.3 Create Text/NLP Based Features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26dbf016",
   "metadata": {},
   "source": [
    "### 2.3.1 Char/Word Count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f8809691",
   "metadata": {},
   "outputs": [],
   "source": [
    "# char_count: total number of characters in the sentence\n",
    "df['char_count'] = df['original_text'].apply(len)\n",
    "\n",
    "# word_count: total number of words in the sentence\n",
    "df['word_count'] = df['original_text'].apply(lambda x: len(x.split()))\n",
    "\n",
    "# word_density: average length of the words used in the documents\n",
    "df['word_density'] = df['char_count'] / (df['word_count']+1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a187da06",
   "metadata": {},
   "source": [
    "### plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83d30d73",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2b8bce35",
   "metadata": {},
   "source": [
    "### 2.3.2 Speech Tag Count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b063b8c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/xinfengliu/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/xinfengliu/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package universal_tagset to\n",
      "[nltk_data]     /Users/xinfengliu/nltk_data...\n",
      "[nltk_data]   Package universal_tagset is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('universal_tagset')\n",
    "\n",
    "def tag_count(x):\n",
    "    # tag each word in the sentence\n",
    "    words = word_tokenize(x)\n",
    "    tag = nltk.pos_tag(words, tagset='universal')\n",
    "    tag_ct = defaultdict(int)\n",
    "    # count tage number\n",
    "    for i in range(len(tag)):\n",
    "        word_type = tag[i][1]\n",
    "        tag_ct[word_type] += 1\n",
    "    return tag_ct\n",
    "\n",
    "df['noun_count'] = df['original_text'].apply(lambda x: tag_count(x)['NOUN'])\n",
    "df['verb_count'] = df['original_text'].apply(lambda x: tag_count(x)['VERB'])\n",
    "df['adj_count'] = df['original_text'].apply(lambda x: tag_count(x)['ADJ'])\n",
    "df['adv_count'] = df['original_text'].apply(lambda x: tag_count(x)['ADV'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0afd627",
   "metadata": {},
   "source": [
    "### plot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e2d7de0",
   "metadata": {},
   "source": [
    "## 2.4 Create Basic Words Count Feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5dd34b8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read simple words data\n",
    "simple_words = pd.read_csv('dale_chall.txt')\n",
    "simple_words = simple_words.rename(columns={'a': 'words'})\n",
    "simp_word_ls = simple_words['words'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "131e98cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simp_word_ct(x):\n",
    "    \"\"\"\n",
    "    input: a sentence in string fromat\n",
    "    \n",
    "    output: percentage of simple words in the sentence\n",
    "    \"\"\"\n",
    "    words = word_tokenize(x)\n",
    "    counter = 0\n",
    "    for i in words:\n",
    "        if i in simp_word_ls:\n",
    "            counter += 1\n",
    "    try:\n",
    "        simple_percent = counter/(len(words))\n",
    "    except ZeroDivisionError:\n",
    "        simple_percent = -1\n",
    "    return simple_percent\n",
    "\n",
    "df['simp_word_percent'] = df['original_text'].apply(lambda x: simp_word_ct(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc53ff8c",
   "metadata": {},
   "source": [
    "## 2.5 Concreteness ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "54870ad4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████| 416768/416768 [01:09<00:00, 5974.75it/s]\n"
     ]
    }
   ],
   "source": [
    "aoa_words = pd.read_csv('AoA_51715_words.csv', encoding = \"ISO-8859-1\")\n",
    "concrete = pd.read_csv('concretness.csv')\n",
    "\n",
    "token = []\n",
    "for each in tqdm(list(df['original_text'])):\n",
    "    token.append(word_tokenize(each))\n",
    "df['token'] = token\n",
    "\n",
    "age_dict = dict(zip(aoa_words['Word'],aoa_words['AoA_Kup_lem']))\n",
    "perc_dict = dict(zip(aoa_words['Word'],aoa_words['Perc_known_lem']))\n",
    "\n",
    "age_mean = np.mean(aoa_words['AoA_Kup_lem'])\n",
    "perc_mean = np.mean(aoa_words['Perc_known_lem'])\n",
    "\n",
    "concrete_dict = dict(zip(concrete['Word'],concrete['Conc.M']))\n",
    "concrete_mean = np.mean(concrete['Conc.M'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a50bdba9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████| 416768/416768 [00:10<00:00, 39088.51it/s]\n"
     ]
    }
   ],
   "source": [
    "avg_age_list = []\n",
    "avg_per_list = []\n",
    "avg_concrete_list = []\n",
    "for each in tqdm(list(df['token'])):\n",
    "    total_age = 0\n",
    "    total_percent = 0\n",
    "    total_concrete = 0\n",
    "    for each_word in each:\n",
    "        if age_dict.get(each_word):\n",
    "            age = age_dict.get(each_word)\n",
    "        else:\n",
    "            age = age_mean\n",
    "        total_age += age\n",
    "\n",
    "        if perc_dict.get(each_word):\n",
    "            percent = perc_dict.get(each_word)\n",
    "        else:\n",
    "            percent = perc_mean\n",
    "        total_percent += percent\n",
    "\n",
    "\n",
    "        if concrete_dict.get(each_word):\n",
    "            concrete_score = concrete_dict.get(each_word)\n",
    "        else:\n",
    "            concrete_score = concrete_mean\n",
    "        total_concrete += concrete_score\n",
    "\n",
    "    if len(each) != 0:\n",
    "        avg_age = total_age / len(each)\n",
    "        avg_percent = total_percent / len(each)\n",
    "        avg_concrete = total_concrete / len(each)\n",
    "    else:\n",
    "        avg_age = age_mean\n",
    "        avg_percent = perc_mean\n",
    "        avg_concrete = concrete_mean\n",
    "    avg_age_list.append(avg_age)\n",
    "    avg_per_list.append(avg_percent)\n",
    "    avg_concrete_list.append(avg_concrete)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "54516b1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['age'] = avg_age_list\n",
    "df['percent_know'] = avg_per_list\n",
    "df['concreteness'] = avg_concrete_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21df88fb",
   "metadata": {},
   "source": [
    "## 2.6 Count of Number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0e23d2db",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████| 416768/416768 [00:01<00:00, 294753.82it/s]\n"
     ]
    }
   ],
   "source": [
    "num_percent_list = []\n",
    "for each in tqdm(list(df['token'])):\n",
    "    num_cnt = 0\n",
    "    for each_word in each:\n",
    "        if each_word.isdigit() == True:\n",
    "            num_cnt += 1\n",
    "\n",
    "  \n",
    "    if len(each) != 0:\n",
    "        number_per = num_cnt / len(each)\n",
    "    else:\n",
    "        number_per = 0\n",
    "\n",
    "    num_percent_list.append(number_per)\n",
    "\n",
    "df['num'] = num_percent_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6142b85",
   "metadata": {},
   "source": [
    "## 2.7 The number of top 100 and least 1000 words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "152edeef",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna()\n",
    "\n",
    "X = df.drop(columns = ['original_text', 'modified_txt',  'label'])\n",
    "y = df['label']\n",
    "\n",
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(X, y, train_size=0.75, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2652de4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████| 312570/312570 [00:14<00:00, 22004.65it/s]\n"
     ]
    }
   ],
   "source": [
    "total_token = []\n",
    "for each in tqdm(X_train['token']):\n",
    "    each = [each_word for each_word in each if each_word not in stop and not each_word.isdigit()]\n",
    "    total_token += each\n",
    "\n",
    "counts = Counter(total_token)\n",
    "\n",
    "sorted_x = dict(sorted(counts.items(), key=lambda item: item[1],reverse=True)[0:100])\n",
    "sorted_x_reverse = dict(sorted(counts.items(), key=lambda item: item[1])[0:1000])\n",
    "\n",
    "top100list = list(sorted_x.keys())\n",
    "least_1000_list = list(sorted_x_reverse.keys())\n",
    "\n",
    "X_train['top100'] = X_train['token'].apply(lambda x: len([w for w in x if w in top100list]))\n",
    "X_test['top100'] = X_test['token'].apply(lambda x: len([w for w in x if w in top100list]))\n",
    "\n",
    "X_train['least1000'] = X_train['token'].apply(lambda x: len([w for w in x if w in least_1000_list]))\n",
    "X_test['least1000'] = X_test['token'].apply(lambda x: len([w for w in x if w in least_1000_list]))\n",
    "\n",
    "X_train.drop(columns=['token'],inplace = True)\n",
    "X_test.drop(columns=['token'],inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39f5ff39",
   "metadata": {},
   "source": [
    "# 3. Model Building"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e863d471",
   "metadata": {},
   "source": [
    "## 3.0 Standardization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ffed1a22",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = preprocessing.MinMaxScaler().fit(X_train)\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c29cc4c1",
   "metadata": {},
   "source": [
    "## 3.1 Dummy Classifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7f85c369",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation Score of Dummy classifier on training set: 0.500\n"
     ]
    }
   ],
   "source": [
    "from sklearn.dummy import DummyClassifier\n",
    "dummy_clf = DummyClassifier().fit(X_train, y_train)\n",
    "dummy_cv_score = cross_val_score(dummy_clf, X_train, y_train, cv=5)\n",
    "print('Cross Validation Score of Dummy classifier on training set: {:.3f}'\n",
    "      .format(dummy_cv_score.mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac1165c8",
   "metadata": {},
   "source": [
    "## 3.2 Logistic Regression Clasifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "421bbe89",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/tf2/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/envs/tf2/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/envs/tf2/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/envs/tf2/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/envs/tf2/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation Score of Logistic Regression classifier on training set: 0.631\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/tf2/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "log_clf = LogisticRegression().fit(X_train, y_train)\n",
    "log_cv_score = cross_val_score(log_clf, X_train, y_train, cv=5)\n",
    "print('Cross Validation Score of Logistic Regression classifier on training set: {:.3f}'\n",
    "      .format(log_cv_score.mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f0b2dc6",
   "metadata": {},
   "source": [
    "## 3.3 SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c8c2e41b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.svm import SVC\n",
    "# svm_clf = SVC().fit(X_train, y_train)\n",
    "# svm_cv_score = cross_val_score(svm_clf, X_train, y_train, cv=5)\n",
    "# print('Cross Validation Score of SVM classifier on training set: {:.3f}'\n",
    "#       .format(dt_cv_score.mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2967d4b6",
   "metadata": {},
   "source": [
    "## 3.4 KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "97c01539",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation Score of KNN classifier on training set: 0.637\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn_clf = KNeighborsClassifier().fit(X_train, y_train)\n",
    "knn_cv_score = cross_val_score(knn_clf, X_train, y_train, cv=5)\n",
    "print('Cross Validation Score of KNN classifier on training set: {:.3f}'\n",
    "      .format(knn_cv_score.mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a763964",
   "metadata": {},
   "source": [
    "## 3.5 Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0fbc41a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation Score of Decision Tree classifier on training set: 0.655\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "dt_clf = DecisionTreeClassifier().fit(X_train, y_train)\n",
    "dt_cv_score = cross_val_score(dt_clf, X_train, y_train, cv=5)\n",
    "print('Cross Validation Score of Decision Tree classifier on training set: {:.3f}'\n",
    "      .format(dt_cv_score.mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0be4460",
   "metadata": {},
   "source": [
    "## 3.6 Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2aed0ca6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation Score of Random Forest classifier on training set: 0.701\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf_clf = RandomForestClassifier().fit(X_train, y_train)\n",
    "rf_cv_score = cross_val_score(rf_clf, X_train, y_train, cv=5)\n",
    "print('Cross Validation Score of Random Forest classifier on training set: {:.3f}'\n",
    "      .format(rf_cv_score.mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d075bb3",
   "metadata": {},
   "source": [
    "## 3.7 AdaBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "52429443",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation Score of AdaBoosting classifier on training set: 0.644\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "adb_clf = AdaBoostClassifier().fit(X_train, y_train)\n",
    "adb_cv_score = cross_val_score(adb_clf, X_train, y_train, cv=5)\n",
    "print('Cross Validation Score of AdaBoosting classifier on training set: {:.3f}'\n",
    "      .format(adb_cv_score.mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3008f323",
   "metadata": {},
   "source": [
    "## 3.8 XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "653ee614",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/tf2/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:40:08] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1637426408905/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/tf2/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:40:38] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1637426408905/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/tf2/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:41:01] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1637426408905/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/tf2/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:41:25] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1637426408905/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/tf2/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:41:44] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1637426408905/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/tf2/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:42:04] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1637426408905/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Cross Validation Score of XGBoosting classifier on training set: 0.664\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "xgb_clf = xgb.XGBClassifier().fit(X_train, y_train)\n",
    "xgb_cv_score = cross_val_score(xgb_clf, X_train, y_train, cv=5)\n",
    "print('Cross Validation Score of XGBoosting classifier on training set: {:.3f}'\n",
    "      .format(xgb_cv_score.mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "482dda96",
   "metadata": {},
   "source": [
    "## 3.9 Recurrent Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "2316dcc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from keras.datasets import imdb\n",
    "# from keras.preprocessing import sequence\n",
    "# from keras.models import Sequential\n",
    "# from keras.layers import Embedding, SimpleRNN\n",
    "# from keras.layers import Flatten, Dense\n",
    "# from keras.layers import LSTM\n",
    "# from keras.preprocessing.text import one_hot\n",
    "# from keras.preprocessing.text import text_to_word_sequence\n",
    "\n",
    "# def one_hot_enc(text):\n",
    "#     words = set(text_to_word_sequence(text))\n",
    "#     vocab_size = len(words)\n",
    "#     result = one_hot(text, round(vocab_size*1.5))\n",
    "#     return result\n",
    "\n",
    "# df['one_hot_enc'] = df['modified_txt'].apply(lambda x: one_hot_enc(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "024bd800",
   "metadata": {},
   "outputs": [],
   "source": [
    "# max_review_length = 500\n",
    "# input_train = df['one_hot_enc']\n",
    "# input_train = sequence.pad_sequences(input_train, maxlen=1000)\n",
    "# # input_test = sequence.pad_sequences(X_test, maxlen=500)\n",
    "\n",
    "# model = Sequential()\n",
    "# model.add(Embedding(10000, 32))\n",
    "# model.add(LSTM(32))\n",
    "# model.add(Flatten())\n",
    "# model.add(Dense(1, activation='sigmoid'))\n",
    "# model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['acc'])\n",
    "# history = model.fit(input_train, y_train,\n",
    "#                     epochs=10,\n",
    "#                     batch_size=32,\n",
    "#                     validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcf827bb",
   "metadata": {},
   "source": [
    "# 4. Result Metric Report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99931dc1",
   "metadata": {},
   "source": [
    "| / | Dummy Classifier | Logistic Regression | KNN | Decision Tree | Random Forest | AdaBoost | XGBoost|\n",
    "| --- | --- | --- | --- | --- | --- | --- | --- |\n",
    "| Accuracy | 0.500 | 0.634 | 0.638 | 0.648 | 0.696 | 0.645 | 0.652|\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d99e9d50",
   "metadata": {},
   "source": [
    "# 5. Best Model Parameter Tunning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ef42ace",
   "metadata": {},
   "source": [
    "## 5.1 GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56c34a0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest\n",
    "n_estimators = [10,100,1000]\n",
    "max_features = [4,6,8,10,12]\n",
    "grid_rf_para = dict(n_estimators = n_estimators, max_features = max_features)\n",
    "rf_clf = RandomForestClassifier()\n",
    "rf_grid_model = GridSearchCV(estimator = rf_clf, param_grid = grid_rf_para, cv=5)\n",
    "rf_grid_result = rf_grid_model.fit(X_train_scaled, y_train)\n",
    "print('Accuracy of Decision Tree classifier after parameter tunning on train set: {:.3f}'\n",
    "      .format(rf_clf.score(X_train_scaled, y_train)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47265e72",
   "metadata": {},
   "source": [
    "## 5.2 Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa122f8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "importances = rf_grid_model.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dec64aeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = np.argsort(importances)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.barh(range(len(importances)), importances[indices])\n",
    "ax.set_yticks(range(len(importances)))\n",
    "_ = ax.set_yticklabels(np.array(X_train.columns)[indices])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b7cd008",
   "metadata": {},
   "source": [
    "# 6. Best Model Accuracy on Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f57da82",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Accuracy of Best Decision Tree classifier after parameter tunning on test set: {:.3f}'\n",
    "      .format(rf_clf.score(X_test_scaled, y_test)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
